{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEI2-l1aTd76"
      },
      "source": [
        "# STOR 566, Homework 3\n",
        "### Instructor: Yao Li\n",
        "### Keywords: LSTM, SST2\n",
        "### Due date: Oct 02, 11:55pm\n",
        "### **Submission Instruction**\n",
        "\n",
        "- Please download this script and use it to answer the questions in the homework. \n",
        "- For submission, please include your code, code output and answers in the script and submit the ipynb file on sakai.\n",
        "- Please don't modify existing cells. But you can add cells between the exercise statements.\n",
        "- To make markdown, please switch the cell type to markdown (from code) - you can hit 'm' when you are in command mode - and use the markdown language. For a brief tutorial see: https://daringfireball.net/projects/markdown/syntax\n",
        "\n",
        "### **References:**\n",
        "\n",
        "- You can follow the setup instructions at [here](https://pytorch.org/get-started/locally/).\n",
        "- A useful tutorial on learning pytorch by examples at [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html).\n",
        "- Check Pytorch optimization methods at [here](https://pytorch.org/docs/stable/optim.html).\n",
        "- Check Torchtext tutorial at [here](https://pytorch.org/text/stable/tutorials/sst2_classification_non_distributed.html).\n",
        "\n",
        "\n",
        "### **Evaluation Metrics of Classifiers:**\n",
        "\n",
        "- Average Test Loss (based on the test set): \n",
        "    \\begin{align}\n",
        "\t  \\frac{1}{B}\\sum_{b=1}^B {\\text loss}_b\n",
        "\t  \\end{align}\n",
        "    \n",
        "    - $B$: the total number of batches from the test set\n",
        "    - loss$_b$: the loss of $b$-th batch\n",
        "    - Note: loss$_b$=criteria(output, target), where criteria is the loss function you use.\n",
        "\n",
        "- Testing accuracy: \n",
        "\t\\begin{align}\n",
        "\t\\frac{1}{N}\\sum_{i=1}^N {\\bf 1}(\\hat{y}_i=y_i)\n",
        "\t\\end{align}\t\n",
        "    - $N$: the total number of samples in the testing set\n",
        "    - $y_i$: true label of sample $i$\n",
        "    - $\\hat{y}_i$: predicted label by the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q_2ulQl15Ig"
      },
      "source": [
        "# Mikhal Ben-Joseph\n",
        "Collaborated with Yesh Munagala as per the Honor Code.\n",
        "I also used these websites to learn more about LSTM and I followed their code example:\n",
        " https://cnvrg.io/pytorch-lstm/\n",
        "\n",
        "https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
        "\n",
        "https://github.com/pytorch/text/blob/main/examples/tutorials/sst2_classification_non_distributed.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dfB-w80VX8M"
      },
      "source": [
        "## Problem 1 (100 points)\n",
        "\n",
        "In this problem you will practice implementing LSTM on SST2 data set to do sentiment analysis (binary classification of positive vs. negative).\n",
        "\n",
        "**Data.** You will use SST2 dataset. Pytorch/torchdata has provide a useful dataloader to automatically download and load the data into batches. In this homework, you need two class, positive and negative, for binary classification. Code of the data loader has been provided in the template. You can modify the data loading part to use different tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyps0ASzWrIR",
        "outputId": "170f4fec-925e-4cef-e194-dcbed9710233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 10 kB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 42.8 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 101 kB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 56.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, idna, charset-normalizer, certifi, torch, requests, portalocker, torchdata\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed certifi-2022.9.24 charset-normalizer-2.1.1 idna-3.4 portalocker-2.5.1 requests-2.28.1 torch-1.12.1 torchdata-0.4.1 typing-extensions-4.3.0 urllib3-1.26.12\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/STOR566/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/STOR566/torchdata already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/STOR566/torchgen already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/STOR566/requests-2.28.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/STOR566/torch already exists. Specify --upgrade to force replacement.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # You need package torchdata for this homework\n",
        "# # To avoid loading it every time, you can install torchdata to a path on google drive\n",
        "# import os\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# pkg_path = '/content/drive/MyDrive/STOR566'\n",
        "# !pip install --target=$pkg_path torchdata\n",
        "\n",
        "# # Append the path to the sys path to load the pkg without re-installation\n",
        "# import sys\n",
        "# pkg_path = '/content/drive/MyDrive/STOR566'\n",
        "# sys.path.append(pkg_path)\n",
        "# import torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLSzuGM_sYuJ",
        "outputId": "fd3e4822-e63c-4617-8ab5-cfbf7ebcc2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_3xFeJ3Fzgn",
        "outputId": "2182afaf-631c-469b-dd4e-304616108c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount your drive\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pkg_path = '/content/drive/MyDrive/STOR566' #Please specify the path where you installed torchdata\n",
        "sys.path.append(pkg_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MRzytmA9F5Ko"
      },
      "outputs": [],
      "source": [
        "# Package Loading\n",
        "# Feel free to add pakcages\n",
        "import torchdata\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext.transforms as T\n",
        "import torchtext.functional as F\n",
        "from torchtext.datasets import SST2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torch.hub import load_state_dict_from_url\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "d80ee505d208481a9f8d4795226a3708",
            "23e00587bda442ec84b93933eb0e0690",
            "586284e333f0400780ec15912ced8280",
            "0b9daf203b28442881f4a378487e5f76",
            "dcf299934b684700ad1fe5b78fd92110",
            "62ee8ed2e3ee4a398a26747637d81668",
            "556ba00dfdf24de4a4a4b770316d5f9d",
            "a3fc4965bb334c2393515d06d1b9427e",
            "9b53717b20e840be80c4f4cdd7a45800",
            "95e7db1ca9084c8abd8aef28eee7ae12",
            "6c0059a6f2f444178ce7225313b430c6"
          ]
        },
        "id": "zLGsNcZ6F7Vj",
        "outputId": "6df625b1-b60b-45b9-a8ac-2357215182ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/text/xlmr.vocab.pt\" to /root/.cache/torch/hub/checkpoints/xlmr.vocab.pt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d80ee505d208481a9f8d4795226a3708",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/4.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.07M/5.07M [00:00<00:00, 29.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Prepare data loader\n",
        "# Feel free to modify the data loading process as needed\n",
        "padding_idx = 1\n",
        "bos_idx = 0\n",
        "eos_idx = 2\n",
        "batch_size = 160\n",
        "max_seq_len = 256\n",
        "# You can use other Tokenizer\n",
        "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "xmlr_vocab = load_state_dict_from_url(xlmr_vocab_path)\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
        "    T.VocabTransform(xmlr_vocab),\n",
        "    T.Truncate(max_seq_len - 2),\n",
        "    T.AddToken(token=bos_idx, begin=True),\n",
        "    T.AddToken(token=eos_idx, begin=False),\n",
        ")\n",
        "\n",
        "train_datapipe = SST2(split=\"train\")\n",
        "test_datapipe = SST2(split=\"dev\")\n",
        "\n",
        "def apply_transform(x):\n",
        "    return text_transform(x[0]), x[1]\n",
        "\n",
        "train_datapipe = train_datapipe.map(apply_transform)\n",
        "train_datapipe = train_datapipe.batch(batch_size)\n",
        "train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
        "train_dataloader = DataLoader(train_datapipe, batch_size=None)\n",
        "\n",
        "test_datapipe = test_datapipe.map(apply_transform)\n",
        "test_datapipe = test_datapipe.batch(batch_size)\n",
        "test_datapipe = test_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
        "test_dataloader = DataLoader(test_datapipe, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hrjP0_HZOe2",
        "outputId": "c4b8ac69-6d15-4560-e788-2a37d9046c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250002\n",
            "250002\n"
          ]
        }
      ],
      "source": [
        "type(xmlr_vocab)\n",
        "print(len(xmlr_vocab))\n",
        "print(len(xmlr_vocab.get_stoi()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzU9SoM_fkAg"
      },
      "source": [
        "### **Problem Description.** Implement **LSTM** with Pytorch to do binary classification.\n",
        "\n",
        "### (a) (15 points) Print the model architecture.\n",
        "\n",
        "(The final model architecture can be seen at the end of this subsection!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idzgh8B269vO",
        "outputId": "025cc6df-8874-497d-e0a3-491e733fba7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device being used is  cuda\n"
          ]
        }
      ],
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device being used is \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iGF6t7r_x-Tr"
      },
      "outputs": [],
      "source": [
        "## Code:\n",
        "\n",
        "class LSTM2(nn.Module):\n",
        "  def __init__(self, vocab, embedding_dim, hidden_dim, output_classes):\n",
        "    super(LSTM2, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    # self.dim = hidden_dim / 2\n",
        "\n",
        "    # Prof told us we need embedding, then LSTM, then MLP\n",
        "    self.embedding = nn.Embedding(vocab, embedding_dim)\n",
        "    # self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim/2, num_layers = 1, batch_first = True, bidirectional = True) #batch_first is just to change order of outputs\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim , num_layers = 1, batch_first = True, bidirectional = True) #batch_first is just to change order of outputs\n",
        "    #note from minji:\n",
        "    #if bidirectional = True:\n",
        "    # input_dim = 2*n_layers*dimension\n",
        "    #else\n",
        "    #  input_dim = n_layers * dimension\n",
        "    \n",
        "    self.mlp = nn.Linear(2*hidden_dim, output_classes)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, words):\n",
        "    # Initialize the first states\n",
        "    # print(torch.is_tensor(words))\n",
        "    # hidden_init = torch.zeros(1, 160, 256).requires_grad_()\n",
        "    # hidden_cell = torch.zeros(1, 160, 256).requires_grad_()\n",
        "    # hidden = hidden_init, hidden_cell\n",
        "\n",
        "    # The components of the LSTM\n",
        "    sentence = words.size()[0]\n",
        "    embedded = self.embedding(words)\n",
        "    # x = embedded.view(len(embedded, 1, -1)) #a form of transpose to make the dimensionality work\n",
        "    # print(\"Successful embed\")\n",
        "    lstm_out , (hidden, _) = self.lstm(embedded)\n",
        "    # print(\"lstm_out info\", type(lstm_out), torch.is_tensor(lstm_out), lstm_out.size() )\n",
        "    # print(\"Successful LSTM\")\n",
        "    hidden = torch.swapaxes(hidden, 0,1)\n",
        "    hidden = hidden.reshape(sentence, 2*self.hidden_dim)\n",
        "    dense = self.mlp(hidden) #redo the transpose\n",
        "    # print(\"Successful MLP\")\n",
        "    # print(\"dense info\", type(dense), torch.is_tensor(dense), dense.size() )\n",
        "    # out = self.sigmoid(dense)\n",
        "    # out = out[:,-1]\n",
        "    # print(\"out info\", type(out), torch.is_tensor(out), out.size() )\n",
        "    # print(dense)\n",
        "    # print(\"dense info\", type(dense), torch.is_tensor(dense), dense.size() )\n",
        "    # dense = dense[:,-1]\n",
        "    # dense = dense[:,-1]\n",
        "    # print(\"dense info\", type(dense), torch.is_tensor(dense), dense.size() )\n",
        "    output = self.sigmoid(dense)\n",
        "\n",
        "    return dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yWTsOPIMEKkc"
      },
      "outputs": [],
      "source": [
        "def hype_tune_LSTM(num_epochs, lr, batch_size):\n",
        "  print(\"\")\n",
        "  print(\" >>>> Number of Epochs: \", num_epochs, \" Learning Rate: \", lr, \" Batch Size: \", batch_size, \"<<<<\")\n",
        "  print(\"\")\n",
        "\n",
        "  ### Intantiating the model\n",
        "  vocab_size = 250002\n",
        "  output_size = 2\n",
        "  embedding_dim = 256\n",
        "  hidden_dim = 256\n",
        "  n_layers = 1\n",
        "\n",
        "  model = LSTM2(vocab = vocab_size, embedding_dim = embedding_dim, hidden_dim = hidden_dim, output_classes = output_size)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  # print(type(model.parameters()))\n",
        "  iter = 0\n",
        "  losses = list()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      epoch_losses = list()\n",
        "\n",
        "      # for i, (images, labels) in enumerate(train_loader):\n",
        "      # for i, (content, labels) in enumerate(train_dataloader):\n",
        "      for batch in train_dataloader:\n",
        "        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "        target = torch.tensor(batch[\"target\"]).to(device)\n",
        "        # target = target.unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # print(type(content))\n",
        "        # print(input)\n",
        "        y_predict = model(input)\n",
        "        #debugging the dimensionality error\n",
        "        _, pred = torch.max(y_predict, 1)\n",
        "        # loss = criterion(pred.float(), target.float())\n",
        "        loss = criterion(pred.float(), target.float())\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        batch_count = iter + 1\n",
        "\n",
        "        epoch_losses.append(loss.item()/batch_count) \n",
        "\n",
        "      ## Save average epoch loss\n",
        "      losses.append(np.average(epoch_losses))\n",
        "      print('Epoch: {} :: Iteration: {} :: Loss: {}  '.format(epoch, iter, losses[-1], ))\n",
        "\n",
        "  return losses, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA0D5dzlxgA_",
        "outputId": "a7102699-6548-450a-f2f4-1d1aa4752db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  1e-05  Batch Size:  160 <<<<\n",
            "\n",
            "<class 'generator'>\n",
            "Epoch: 0 :: Iteration: 421 :: Loss: 0.7214285456088144  \n",
            "Epoch: 1 :: Iteration: 842 :: Loss: 0.09043837049403766  \n",
            "Epoch: 2 :: Iteration: 1263 :: Loss: 0.052985503843495034  \n",
            "Epoch: 3 :: Iteration: 1684 :: Loss: 0.03761625998813214  \n",
            "Epoch: 4 :: Iteration: 2105 :: Loss: 0.02918674481968832  \n",
            "Epoch: 5 :: Iteration: 2526 :: Loss: 0.023852054751749487  \n",
            "Epoch: 6 :: Iteration: 2947 :: Loss: 0.02016937324970968  \n",
            "Epoch: 7 :: Iteration: 3368 :: Loss: 0.017473239055330502  \n",
            "Epoch: 8 :: Iteration: 3789 :: Loss: 0.01541365235519091  \n",
            "Epoch: 9 :: Iteration: 4210 :: Loss: 0.013788800302599097  \n"
          ]
        }
      ],
      "source": [
        "losses2, model2 = hype_tune_LSTM(10, 0.00001, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1FOAPoDzGh-",
        "outputId": "a8e9a901-0ef1-4f5e-8611-095181e8dc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM2(\n",
            "  (embedding): Embedding(250002, 256)\n",
            "  (lstm): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "  (mlp): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh9BodM3jvF_",
        "outputId": "63cfc906-8c2b-4f98-cd68-bcbcc74a323f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  0.001  Batch Size:  160 <<<<\n",
            "\n",
            "<class 'generator'>\n",
            "Epoch: 0 :: Iteration: 421 :: Loss: 0.7307925483648567  \n",
            "Epoch: 1 :: Iteration: 842 :: Loss: 0.09047917781599972  \n",
            "Epoch: 2 :: Iteration: 1263 :: Loss: 0.05298273719526097  \n",
            "Epoch: 3 :: Iteration: 1684 :: Loss: 0.03760695729064807  \n",
            "Epoch: 4 :: Iteration: 2105 :: Loss: 0.029176491645895444  \n",
            "Epoch: 5 :: Iteration: 2526 :: Loss: 0.023842132779994717  \n",
            "Epoch: 6 :: Iteration: 2947 :: Loss: 0.020160092977149956  \n",
            "Epoch: 7 :: Iteration: 3368 :: Loss: 0.017464639404590213  \n",
            "Epoch: 8 :: Iteration: 3789 :: Loss: 0.015405691423772811  \n",
            "Epoch: 9 :: Iteration: 4210 :: Loss: 0.013781415279558763  \n"
          ]
        }
      ],
      "source": [
        "losses1, model1 = hype_tune_LSTM(10, 0.001, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9LGutPvdH7",
        "outputId": "85cf4994-9758-4902-bc3e-b400e1077628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM2(\n",
            "  (embedding): Embedding(250002, 256)\n",
            "  (lstm): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "  (mlp): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEhHi-jfNQyJ",
        "outputId": "a875d021-0b67-46d5-887a-c383b3cc4f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  0.01  Batch Size:  160 <<<<\n",
            "\n",
            "<class 'generator'>\n",
            "Epoch: 0 :: Iteration: 421 :: Loss: 0.6027478291212  \n",
            "Epoch: 1 :: Iteration: 842 :: Loss: 0.07274841002143442  \n",
            "Epoch: 2 :: Iteration: 1263 :: Loss: 0.042588758144343035  \n",
            "Epoch: 3 :: Iteration: 1684 :: Loss: 0.030227161245417293  \n",
            "Epoch: 4 :: Iteration: 2105 :: Loss: 0.023450318339802507  \n",
            "Epoch: 5 :: Iteration: 2526 :: Loss: 0.0191625623891092  \n",
            "Epoch: 6 :: Iteration: 2947 :: Loss: 0.01620304517769227  \n",
            "Epoch: 7 :: Iteration: 3368 :: Loss: 0.014036565124498497  \n",
            "Epoch: 8 :: Iteration: 3789 :: Loss: 0.012381702990283926  \n",
            "Epoch: 9 :: Iteration: 4210 :: Loss: 0.011076218315117145  \n"
          ]
        }
      ],
      "source": [
        "losses0, model0 = hype_tune_LSTM(10, 0.01, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pQcClqGn9ae5"
      },
      "outputs": [],
      "source": [
        "### SGD OPTIMIZER VERSION\n",
        "\n",
        "def hype_tune_LSTM_SGD(num_epochs, lr, batch_size, momentum):\n",
        "  print(\"\")\n",
        "  print(\" >>>> Number of Epochs: \", num_epochs, \" Learning Rate: \", lr, \" Batch Size: \", batch_size, \"<<<<\")\n",
        "  print(\"\")\n",
        "\n",
        "  ### Intantiating the model\n",
        "  vocab_size = 250002\n",
        "  output_size = 2\n",
        "  embedding_dim = 256\n",
        "  hidden_dim = 256\n",
        "  n_layers = 1\n",
        "\n",
        "  model = LSTM2(vocab = vocab_size, embedding_dim = embedding_dim, hidden_dim = hidden_dim, output_classes = output_size)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = momentum)\n",
        "  # print(type(model.parameters()))\n",
        "  iter = 0\n",
        "  losses = list()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      epoch_losses = list()\n",
        "\n",
        "      # for i, (images, labels) in enumerate(train_loader):\n",
        "      # for i, (content, labels) in enumerate(train_dataloader):\n",
        "      for batch in train_dataloader:\n",
        "        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "        target = torch.tensor(batch[\"target\"]).to(device)\n",
        "        # target = target.unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # print(type(content))\n",
        "        # print(input)\n",
        "        y_predict = model(input)\n",
        "        #debugging the dimensionality error\n",
        "        _, pred = torch.max(y_predict, 1)\n",
        "        # loss = criterion(pred.float(), target.float())\n",
        "        loss = criterion(pred.float(), target.float())\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        batch_count = iter + 1\n",
        "\n",
        "        epoch_losses.append(loss.item()/batch_count) \n",
        "\n",
        "      ## Save average epoch loss\n",
        "      losses.append(np.average(epoch_losses))\n",
        "      print('Epoch: {} :: Iteration: {} :: Loss: {}  '.format(epoch, iter, losses[-1], ))\n",
        "\n",
        "  return losses, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoQRqPwu9rIc",
        "outputId": "36b7bdd5-9116-4298-9818-2341910d6486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  0.01  Batch Size:  160 <<<<\n",
            "\n",
            "Epoch: 0 :: Iteration: 421 :: Loss: 0.6035642941318369  \n",
            "Epoch: 1 :: Iteration: 842 :: Loss: 0.07271234345011267  \n",
            "Epoch: 2 :: Iteration: 1263 :: Loss: 0.04256875870813011  \n",
            "Epoch: 3 :: Iteration: 1684 :: Loss: 0.03021326935013102  \n",
            "Epoch: 4 :: Iteration: 2105 :: Loss: 0.023439662882887694  \n",
            "Epoch: 5 :: Iteration: 2526 :: Loss: 0.019153915907768996  \n",
            "Epoch: 6 :: Iteration: 2947 :: Loss: 0.016195768537233535  \n",
            "Epoch: 7 :: Iteration: 3368 :: Loss: 0.014030282830134702  \n",
            "Epoch: 8 :: Iteration: 3789 :: Loss: 0.012376175542704109  \n",
            "Epoch: 9 :: Iteration: 4210 :: Loss: 0.011071283544223817  \n"
          ]
        }
      ],
      "source": [
        "losses3, model3 = hype_tune_LSTM_SGD(10, 0.01, 160, 0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frryekc19yN4",
        "outputId": "aabec8fd-fa7a-4877-cc8f-9bdb0d9e4e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  0.01  Batch Size:  160 <<<<\n",
            "\n",
            "Epoch: 0 :: Iteration: 421 :: Loss: 0.6036504820579802  \n",
            "Epoch: 1 :: Iteration: 842 :: Loss: 0.072657910470934  \n",
            "Epoch: 2 :: Iteration: 1263 :: Loss: 0.042535309320789444  \n",
            "Epoch: 3 :: Iteration: 1684 :: Loss: 0.030189070226952632  \n",
            "Epoch: 4 :: Iteration: 2105 :: Loss: 0.023420693057705822  \n",
            "Epoch: 5 :: Iteration: 2526 :: Loss: 0.01913831276381867  \n",
            "Epoch: 6 :: Iteration: 2947 :: Loss: 0.016182515537693887  \n",
            "Epoch: 7 :: Iteration: 3368 :: Loss: 0.014018763938001116  \n",
            "Epoch: 8 :: Iteration: 3789 :: Loss: 0.012365989078831994  \n",
            "Epoch: 9 :: Iteration: 4210 :: Loss: 0.011062153003741993  \n"
          ]
        }
      ],
      "source": [
        "losses4, model4 = hype_tune_LSTM_SGD(10, 0.01, 160, 0.95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kATUxyK33WuF",
        "outputId": "ea2301f5-062d-43ea-84d7-e5d5e3eb9e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.011062153003741993\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "list_of_losses = [losses0[-1], losses1[-1], losses2[-1], losses3[-1], losses4[-1]]\n",
        "min_loss = min(list_of_losses)\n",
        "print(min_loss)\n",
        "min_params = list_of_losses.index(min_loss)\n",
        "print(min_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lGFBvyeImWf",
        "outputId": "dbe4e9e3-8428-4673-dca8-3cf112cf1fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model architecture is:  LSTM2(\n",
            "  (embedding): Embedding(250002, 256)\n",
            "  (lstm): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "  (mlp): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"The model architecture is: \" , model4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review with Minji\n",
        "# binary text classification pytorch info for SST-2\n",
        "# LST pytorch website \"LSTMTagger\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSd9yYv8fu2K"
      },
      "source": [
        "### (b) (10 points) Report the hyper-parameters (number of epochs, learning rate, momentum, weight_decay etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyaK8gHOgch-"
      },
      "source": [
        "Answer: \n",
        "I started by using the Adam optimizer with a variety of learning rates and no weight decay and found that a LR of 0.01 yielded the smallest loss of the Adam-optimized model. Then, I ran the model with the SGD optimizer with LR of 0.01 and two different momentums. The lowest loss occurred with the following hyperparameters:\n",
        "\n",
        "- 10 epochs\n",
        "- LR = 0.01\n",
        "- momentum = 0.95\n",
        "- No weight decay\n",
        "- batch size = 160\n",
        "- optimizer = SGD with momentum\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWkYLZMxgapU"
      },
      "source": [
        "### (c) (60 points) Report the **Average Test Loss** after every training epoch by generating Average Test Loss vs. Epoch plot. Please report at least **10** epochs. Note that **Average Test Loss** is based on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UE2kSHxzg29o"
      },
      "outputs": [],
      "source": [
        "## Code:\n",
        "\n",
        "def Test_LSTM(model, num_epochs, lr, batch_size):\n",
        "  print(\"\")\n",
        "  print(\" >>>> Number of Epochs: \", num_epochs, \" Learning Rate: \", lr, \" Batch Size: \", batch_size, \"<<<<\")\n",
        "  print(\"\")\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  losses = []\n",
        "  iter = 0\n",
        "\n",
        "  model.to(device)\n",
        "  # print(model.device)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      epoch_losses = list()\n",
        "\n",
        "      for batch in test_dataloader:\n",
        "        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "        target = torch.tensor(batch[\"target\"]).to(device)\n",
        "        # print(input.device)\n",
        "        # print(target.device)\n",
        "\n",
        "        y_predict = model(input)\n",
        "        _, pred = torch.max(y_predict, 1)\n",
        "        loss = criterion(pred.float(), target.float())\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        iter += 1\n",
        "        batch_count = iter + 1\n",
        "\n",
        "        epoch_losses.append(loss.item()/batch_count) \n",
        "\n",
        "      ## Save average epoch loss\n",
        "      losses.append(np.average(epoch_losses))\n",
        "      print('Epoch: {} :: Iteration: {} :: Loss: {}  '.format(epoch, iter, losses[-1], ))\n",
        "\n",
        "  return losses, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTloLdx3xG4k",
        "outputId": "736b96c6-11ab-4bb5-8017-05520db7c15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " >>>> Number of Epochs:  10  Learning Rate:  0.01  Batch Size:  160 <<<<\n",
            "\n",
            "Epoch: 0 :: Iteration: 6 :: Loss: 12.92824073064895  \n",
            "Epoch: 1 :: Iteration: 12 :: Loss: 4.784914443542907  \n",
            "Epoch: 2 :: Iteration: 18 :: Loss: 2.998585870690215  \n",
            "Epoch: 3 :: Iteration: 24 :: Loss: 2.18905001468899  \n",
            "Epoch: 4 :: Iteration: 30 :: Loss: 1.724938432684671  \n",
            "Epoch: 5 :: Iteration: 36 :: Loss: 1.4235974803968638  \n",
            "Epoch: 6 :: Iteration: 42 :: Loss: 1.2120446759164634  \n",
            "Epoch: 7 :: Iteration: 48 :: Loss: 1.05530631981847  \n",
            "Epoch: 8 :: Iteration: 54 :: Loss: 0.9345018910559952  \n",
            "Epoch: 9 :: Iteration: 60 :: Loss: 0.8385354687877223  \n"
          ]
        }
      ],
      "source": [
        "test_losses, test_model = Test_LSTM(model4, 10, 0.01, 160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0yM6NLFig4bF",
        "outputId": "40b5358d-b1ab-4d76-d085-79aa442b059e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Plot:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(0, len(test_losses)), test_losses)\n",
        "plt.title(\"Average Test Loss vs. Epoch\")\n",
        "plt.ylabel(\"Average Test Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv2InAYwg5j1"
      },
      "source": [
        "### (d) (15 points) Report the final testing accuracy of trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV5q13bz0emV",
        "outputId": "6e697256-999b-44ea-96a2-127e9c473020"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:249: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy is:  0.981651376146789\n"
          ]
        }
      ],
      "source": [
        "iters = 0 \n",
        "correct = 0\n",
        "\n",
        "for data in test_dataloader:\n",
        "  # input = F.to_tensor(data[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "  target = torch.tensor(data[\"target\"]).to(device).reshape(-1,1)\n",
        "  # print(input.device)\n",
        "  # print(target.device)\n",
        "\n",
        "  # y_predict = model4(input)\n",
        "  # _, pred = torch.max(y_predict, 1)\n",
        "  y_predict = (torch.sign(model4(F.to_tensor(data['token_ids'], padding_value = padding_idx).to(device))-0.5)+1)/2\n",
        "  iters += target.size(0)\n",
        "  correct += (y_predict == target).sum().item()\n",
        "\n",
        "accuracy = correct / iters\n",
        "print(f\"Test Accuracy is: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bt2-kE9hHtB"
      },
      "source": [
        "Answer:\n",
        "\n",
        "The final test accuracy of the trained model which we chose is approximately 0.9817."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b9daf203b28442881f4a378487e5f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e7db1ca9084c8abd8aef28eee7ae12",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0059a6f2f444178ce7225313b430c6",
            "value": " 4.85M/4.85M [00:00&lt;00:00, 71.1MB/s]"
          }
        },
        "23e00587bda442ec84b93933eb0e0690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62ee8ed2e3ee4a398a26747637d81668",
            "placeholder": "​",
            "style": "IPY_MODEL_556ba00dfdf24de4a4a4b770316d5f9d",
            "value": "100%"
          }
        },
        "556ba00dfdf24de4a4a4b770316d5f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "586284e333f0400780ec15912ced8280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3fc4965bb334c2393515d06d1b9427e",
            "max": 5082095,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b53717b20e840be80c4f4cdd7a45800",
            "value": 5082095
          }
        },
        "62ee8ed2e3ee4a398a26747637d81668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0059a6f2f444178ce7225313b430c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e7db1ca9084c8abd8aef28eee7ae12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b53717b20e840be80c4f4cdd7a45800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3fc4965bb334c2393515d06d1b9427e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d80ee505d208481a9f8d4795226a3708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23e00587bda442ec84b93933eb0e0690",
              "IPY_MODEL_586284e333f0400780ec15912ced8280",
              "IPY_MODEL_0b9daf203b28442881f4a378487e5f76"
            ],
            "layout": "IPY_MODEL_dcf299934b684700ad1fe5b78fd92110"
          }
        },
        "dcf299934b684700ad1fe5b78fd92110": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
